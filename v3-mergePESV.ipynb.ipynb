{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1m8kVmEb4eeOEISCouyCWkaNcXCPKNtCC","authorship_tag":"ABX9TyPzM+tUggHrMckqs2LTbIzY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R66aLC0aj-72","executionInfo":{"status":"ok","timestamp":1762590362648,"user_tz":-420,"elapsed":6096,"user":{"displayName":"Hanif Nur Ilham Sanjaya","userId":"10100194631026074709"}},"outputId":"2265d0cc-eab6-45a8-8d25-94281b8c39f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- Initializing PESV v3 Assembly Script ---\n","All libraries imported successfully.\n","Loading component files...\n","--- Initial Shapes ---\n","Base Labels (from CNN): (9720, 4)\n","Alpha'' (CNN features): (9720, 129)\n","Delta (Flow Stats):     (10105, 43)\n","Gamma' (Burst Stats):   (10105, 41)\n","\n","Merging... (using 'filename' as the key)\n","Shape after merging Alpha'': (9720, 132)\n","Shape after merging Delta:  (9542, 171)\n","Shape after merging Gamma': (9542, 208)\n","\n","Assembly complete. Saving final dataset...\n","\n","--- Successfully Created /content/drive/MyDrive/1 Skripsi/final_PESV_dataset_v3.csv ---\n","Final Dataset Shape: (9542, 208)\n","\n","Final Dataset Info:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 9542 entries, 0 to 9541\n","Columns: 208 entries, filename to burst_idle_p75\n","dtypes: float64(203), int64(1), object(4)\n","memory usage: 15.1+ MB\n"]}],"source":["# --- Final PESV (v3) Assembly Script ---\n","#\n","# This script assembles the \"ultimate\" feature vector:\n","# Sigma_v3 = (alpha'' + delta + gamma')\n","#\n","# 1. Base (Labels): cnn_payload_labels.csv (9,720 samples)\n","# 2. Alpha'' (α''): alpha_double_prime_component_v3.csv (128 features)\n","# 3. Delta (δ):     delta_component_v2.csv (~39 features)\n","# 4. Gamma' (γ'):   gamma_prime_component_v2.csv (37 features)\n","#\n","# It performs an 'inner merge' on 'filename' to ensure\n","# only flows valid across all three pipelines are included.\n","\n","print(\"--- Initializing PESV v3 Assembly Script ---\")\n","\n","import pandas as pd\n","import os\n","\n","print(\"All libraries imported successfully.\")\n","\n","# --- PART 1: Configuration ---\n","BASE_PATH = \"/content/drive/MyDrive/1 Skripsi/\"\n","\n","# --- Input Files ---\n","# 1. This is our \"base\" file. It has the 9,720 valid filenames and labels.\n","BASE_LABELS_FILE = os.path.join(BASE_PATH, \"VPNOnly-cnn_payload_labels.csv\")\n","\n","# 2. The new 1D-CNN features\n","ALPHA_V3_FILE = os.path.join(BASE_PATH, \"VPNOnly-alpha_double_prime_component_v3.csv\")\n","\n","# 3. The statistical features (from our v2 run)\n","DELTA_V2_FILE = os.path.join(BASE_PATH, \"VPNOnly-delta_component_v2.csv\")\n","GAMMA_V2_FILE = os.path.join(BASE_PATH, \"VPNOnly-gamma_prime_component_v2.csv\")\n","\n","# --- Output File ---\n","OUTPUT_FILE = os.path.join(BASE_PATH, \"VPNOnly-final_PESV_dataset_v3.csv\")\n","\n","# --- PART 2: Main Assembly ---\n","def main():\n","    print(\"Loading component files...\")\n","\n","    try:\n","        # Load the base labels (9,720 rows)\n","        df_base_labels = pd.read_csv(BASE_LABELS_FILE)\n","\n","        # Load the new alpha'' features (9,720 rows)\n","        df_alpha_pp = pd.read_csv(ALPHA_V3_FILE)\n","\n","        # Load the delta features (~10k rows)\n","        df_delta = pd.read_csv(DELTA_V2_FILE)\n","\n","        # Load the gamma' features (~10k rows)\n","        df_gamma = pd.read_csv(GAMMA_V2_FILE)\n","\n","    except FileNotFoundError as e:\n","        print(f\"FATAL ERROR: Could not find a file. {e}\")\n","        print(\"Please ensure all component files exist:\")\n","        print(f\" - {BASE_LABELS_FILE}\")\n","        print(f\" - {ALPHA_V3_FILE}\")\n","        print(f\" - {DELTA_V2_FILE}\")\n","        print(f\" - {GAMMA_V2_FILE}\")\n","        return\n","\n","    print(\"--- Initial Shapes ---\")\n","    print(f\"Base Labels (from CNN): {df_base_labels.shape}\")\n","    print(f\"Alpha'' (CNN features): {df_alpha_pp.shape}\")\n","    print(f\"Delta (Flow Stats):     {df_delta.shape}\")\n","    print(f\"Gamma' (Burst Stats):   {df_gamma.shape}\")\n","\n","    # --- Prepare feature dataframes for merging ---\n","    # The delta and gamma files contain redundant label columns.\n","    # We must drop them before merging to avoid conflicts.\n","    label_cols_to_drop = ['application', 'category', 'binary_type']\n","\n","    # Select only filename + delta features\n","    delta_feature_cols = [col for col in df_delta.columns if col not in label_cols_to_drop]\n","    df_delta_features_only = df_delta[delta_feature_cols]\n","\n","    # Select only filename + gamma' features\n","    gamma_feature_cols = [col for col in df_gamma.columns if col not in label_cols_to_drop]\n","    df_gamma_features_only = df_gamma[gamma_feature_cols]\n","\n","    # --- Perform Sequential Inner Merge ---\n","    # This robustly finds the common set of 'filename' keys\n","\n","    print(\"\\nMerging... (using 'filename' as the key)\")\n","\n","    # 1. Merge Base Labels + Alpha'' features\n","    # (This should be a perfect 1-to-1 merge, 9,720 rows)\n","    df_merged = pd.merge(df_base_labels, df_alpha_pp, on='filename', how='inner')\n","    print(f\"Shape after merging Alpha'': {df_merged.shape}\")\n","\n","    # 2. Merge with Delta features\n","    df_merged = pd.merge(df_merged, df_delta_features_only, on='filename', how='inner')\n","    print(f\"Shape after merging Delta:  {df_merged.shape}\")\n","\n","    # 3. Merge with Gamma' features\n","    df_final = pd.merge(df_merged, df_gamma_features_only, on='filename', how='inner')\n","    print(f\"Shape after merging Gamma': {df_final.shape}\")\n","\n","    # --- Save Final Dataset ---\n","    print(f\"\\nAssembly complete. Saving final dataset...\")\n","    df_final.to_csv(OUTPUT_FILE, index=False)\n","\n","    print(f\"\\n--- Successfully Created {OUTPUT_FILE} ---\")\n","    print(f\"Final Dataset Shape: {df_final.shape}\")\n","\n","    # Display info\n","    print(\"\\nFinal Dataset Info:\")\n","    df_final.info()\n","\n","if __name__ == \"__main__\":\n","    if not os.path.exists(\"/content/drive/MyDrive\"):\n","        print(\"Please mount your Google Drive first!\")\n","    else:\n","        main()"]},{"cell_type":"code","source":["# --- Final PESV (v3) Assembly Script ---\n","#\n","# This script assembles the \"ultimate\" feature vector:\n","# Sigma_v3 = (alpha'' + delta + gamma')\n","#\n","# 1. Base (Labels): cnn_payload_labels.csv (9,720 samples)\n","# 2. Alpha'' (α''): alpha_double_prime_component_v3.csv (128 features)\n","# 3. Delta (δ):     delta_component_v2.csv (~39 features)\n","# 4. Gamma' (γ'):   gamma_prime_component_v2.csv (37 features)\n","#\n","# It performs an 'inner merge' on 'filename' to ensure\n","# only flows valid across all three pipelines are included.\n","\n","print(\"--- Initializing PESV v3 Assembly Script ---\")\n","\n","import pandas as pd\n","import os\n","\n","print(\"All libraries imported successfully.\")\n","\n","# --- PART 1: Configuration ---\n","BASE_PATH = \"/content/drive/MyDrive/1 Skripsi/\"\n","\n","# --- Input Files ---\n","# 1. This is our \"base\" file. It has the 9,720 valid filenames and labels.\n","BASE_LABELS_FILE = os.path.join(BASE_PATH, \"VPNOnly-cnn_payload_labels.csv\")\n","\n","# 2. The new 1D-CNN features\n","ALPHA_V3_FILE = os.path.join(BASE_PATH, \"VPNOnly-alpha_double_prime_component_v3.csv\")\n","\n","# 3. The statistical features (from our v2 run)\n","DELTA_V2_FILE = os.path.join(BASE_PATH, \"VPNOnly-delta_component_v2.csv\")\n","GAMMA_V2_FILE = os.path.join(BASE_PATH, \"VPNOnly-gamma_prime_component_v2.csv\")\n","\n","# --- Output File ---\n","OUTPUT_FILE = os.path.join(BASE_PATH, \"VPNOnly-final_PESV_dataset_v3.csv\")\n","\n","# --- PART 2: Main Assembly ---\n","def main():\n","    print(\"Loading component files...\")\n","\n","    try:\n","        # Load the base labels (9,720 rows)\n","        df_base_labels = pd.read_csv(BASE_LABELS_FILE)\n","\n","        # Load the new alpha'' features (9,720 rows)\n","        df_alpha_pp = pd.read_csv(ALPHA_V3_FILE)\n","\n","        # Load the delta features (~10k rows)\n","        df_delta = pd.read_csv(DELTA_V2_FILE)\n","\n","        # Load the gamma' features (~10k rows)\n","        df_gamma = pd.read_csv(GAMMA_V2_FILE)\n","\n","    except FileNotFoundError as e:\n","        print(f\"FATAL ERROR: Could not find a file. {e}\")\n","        print(\"Please ensure all component files exist:\")\n","        print(f\" - {BASE_LABELS_FILE}\")\n","        print(f\" - {ALPHA_V3_FILE}\")\n","        print(f\" - {DELTA_V2_FILE}\")\n","        print(f\" - {GAMMA_V2_FILE}\")\n","        return\n","\n","    print(\"--- Initial Shapes ---\")\n","    print(f\"Base Labels (from CNN): {df_base_labels.shape}\")\n","    print(f\"Alpha'' (CNN features): {df_alpha_pp.shape}\")\n","    print(f\"Delta (Flow Stats):     {df_delta.shape}\")\n","    print(f\"Gamma' (Burst Stats):   {df_gamma.shape}\")\n","\n","    # --- Prepare feature dataframes for merging ---\n","    # The delta and gamma files contain redundant label columns.\n","    # We must drop them before merging to avoid conflicts.\n","    label_cols_to_drop = ['application', 'category', 'binary_type']\n","\n","    # Select only filename + delta features\n","    delta_feature_cols = [col for col in df_delta.columns if col not in label_cols_to_drop]\n","    df_delta_features_only = df_delta[delta_feature_cols]\n","\n","    # Select only filename + gamma' features\n","    gamma_feature_cols = [col for col in df_gamma.columns if col not in label_cols_to_drop]\n","    df_gamma_features_only = df_gamma[gamma_feature_cols]\n","\n","    # --- Perform Sequential Inner Merge ---\n","    # This robustly finds the common set of 'filename' keys\n","\n","    print(\"\\nMerging... (using 'filename' as the key)\")\n","\n","    # 1. Merge Base Labels + Alpha'' features\n","    # (This should be a perfect 1-to-1 merge, 9,720 rows)\n","    df_merged = pd.merge(df_base_labels, df_alpha_pp, on='filename', how='inner')\n","    print(f\"Shape after merging Alpha'': {df_merged.shape}\")\n","\n","    # 2. Merge with Delta features\n","    df_merged = pd.merge(df_merged, df_delta_features_only, on='filename', how='inner')\n","    print(f\"Shape after merging Delta:  {df_merged.shape}\")\n","\n","    # 3. Merge with Gamma' features\n","    df_final = pd.merge(df_merged, df_gamma_features_only, on='filename', how='inner')\n","    print(f\"Shape after merging Gamma': {df_final.shape}\")\n","\n","    # --- Save Final Dataset ---\n","    print(f\"\\nAssembly complete. Saving final dataset...\")\n","    df_final.to_csv(OUTPUT_FILE, index=False)\n","\n","    print(f\"\\n--- Successfully Created {OUTPUT_FILE} ---\")\n","    print(f\"Final Dataset Shape: {df_final.shape}\")\n","\n","    # Display info\n","    print(\"\\nFinal Dataset Info:\")\n","    df_final.info()\n","\n","if __name__ == \"__main__\":\n","    if not os.path.exists(\"/content/drive/MyDrive\"):\n","        print(\"Please mount your Google Drive first!\")\n","    else:\n","        main()"],"metadata":{"id":"jtpg5b1Ikf28","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762603331737,"user_tz":-420,"elapsed":6879,"user":{"displayName":"Hanif Nur Ilham Sanjaya","userId":"10100194631026074709"}},"outputId":"1d1f7842-f68c-400c-b509-56dff46f6f27"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Initializing PESV v3 Assembly Script ---\n","All libraries imported successfully.\n","Loading component files...\n","--- Initial Shapes ---\n","Base Labels (from CNN): (2623, 4)\n","Alpha'' (CNN features): (2623, 129)\n","Delta (Flow Stats):     (2730, 43)\n","Gamma' (Burst Stats):   (2730, 41)\n","\n","Merging... (using 'filename' as the key)\n","Shape after merging Alpha'': (2623, 132)\n","Shape after merging Delta:  (2623, 171)\n","Shape after merging Gamma': (2623, 208)\n","\n","Assembly complete. Saving final dataset...\n","\n","--- Successfully Created /content/drive/MyDrive/1 Skripsi/VPNOnly-final_PESV_dataset_v3.csv ---\n","Final Dataset Shape: (2623, 208)\n","\n","Final Dataset Info:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 2623 entries, 0 to 2622\n","Columns: 208 entries, filename to burst_idle_p75\n","dtypes: float64(203), int64(1), object(4)\n","memory usage: 4.2+ MB\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ahKaQ6W3WBtr"},"execution_count":null,"outputs":[]}]}