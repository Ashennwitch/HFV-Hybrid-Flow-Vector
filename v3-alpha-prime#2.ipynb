{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1c9dyq8Rm1A60ALwpkt8gxZxjiEQYbeZb","authorship_tag":"ABX9TyMtGzmyBSkqfQHnBa9TFkwI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"G3j9Xp4LhN-O","executionInfo":{"status":"ok","timestamp":1762603174172,"user_tz":-420,"elapsed":64325,"user":{"displayName":"Hanif Nur Ilham Sanjaya","userId":"10100194631026074709"}},"outputId":"3fee577a-4efe-4460-f161-98bb81fa960d"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- Initializing 1D-CNN Feature Extractor (Step 2) ---\n","TensorFlow Version: 2.19.0\n","Loading data from /content/drive/MyDrive/1 Skripsi/VPNOnly-cnn_payload_data.npy...\n","Loaded data shape: (2623, 10, 784)\n","Loaded labels shape: (2623, 4)\n","Reshaped X to: (2623, 7840, 1)\n","Target label: 'application' with 9 classes.\n","y shape after one-hot encoding: (2623, 9)\n","Training data: (2098, 7840, 1), Validation data: (525, 7840, 1)\n","Building 1D-CNN model...\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"functional\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7840\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7840\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1960\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1960\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m10,304\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m490\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m490\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m24,704\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m122\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15616\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ encoder_output (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,998,976\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ classifier_output (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │         \u001b[38;5;34m1,161\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7840</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7840</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1960</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1960</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">490</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">490</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">122</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15616</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ encoder_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,998,976</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ classifier_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,161</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,035,401\u001b[0m (7.76 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,035,401</span> (7.76 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,035,401\u001b[0m (7.76 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,035,401</span> (7.76 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["None\n","\n","--- Starting 1D-CNN Training ---\n","Epoch 1/100\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 203ms/step - accuracy: 0.5212 - loss: 1.5601 - val_accuracy: 0.8076 - val_loss: 0.6238\n","Epoch 2/100\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.8066 - loss: 0.6498 - val_accuracy: 0.8495 - val_loss: 0.4676\n","Epoch 3/100\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.8635 - loss: 0.4269 - val_accuracy: 0.8610 - val_loss: 0.4515\n","Epoch 4/100\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.8775 - loss: 0.3487 - val_accuracy: 0.8686 - val_loss: 0.4019\n","Epoch 5/100\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9055 - loss: 0.2793 - val_accuracy: 0.8762 - val_loss: 0.4061\n","Epoch 6/100\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.8999 - loss: 0.2790 - val_accuracy: 0.8762 - val_loss: 0.4124\n","Epoch 7/100\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9082 - loss: 0.2612 - val_accuracy: 0.8762 - val_loss: 0.4265\n","Epoch 8/100\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9117 - loss: 0.2440 - val_accuracy: 0.8876 - val_loss: 0.4127\n","Epoch 9/100\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9067 - loss: 0.2392 - val_accuracy: 0.8762 - val_loss: 0.4403\n","Epoch 10/100\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9257 - loss: 0.2081 - val_accuracy: 0.8857 - val_loss: 0.4505\n","Epoch 11/100\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9098 - loss: 0.2211 - val_accuracy: 0.8819 - val_loss: 0.4352\n","Epoch 12/100\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9373 - loss: 0.1618 - val_accuracy: 0.8743 - val_loss: 0.4128\n","Epoch 13/100\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9303 - loss: 0.1854 - val_accuracy: 0.8838 - val_loss: 0.4297\n","Epoch 14/100\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9381 - loss: 0.1695 - val_accuracy: 0.8724 - val_loss: 0.4748\n","--- Training Complete ---\n","Extracting and saving the encoder model...\n","Encoder model saved to: /content/drive/MyDrive/1 Skripsi/VPNOnly-cnn_encoder_v3.keras\n","Generating 128-dimension alpha'' features for all 2623 samples...\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n","Generated features with shape: (2623, 128)\n","New alpha'' (v3) component saved to: /content/drive/MyDrive/1 Skripsi/VPNOnly-alpha_double_prime_component_v3.csv\n","\n","--- 1D-CNN Feature Extractor Finished ---\n"]}],"source":["# --- 1D-CNN Feature Extractor Script (Step 2) ---\n","#\n","# This script loads the raw payload data created by Step 1,\n","# trains a 1D-CNN to classify applications (as suggested by\n","# the research papers), and then saves the trained \"encoder\"\n","# part of the model.\n","#\n","# It then uses this encoder to generate our new 128-dimension\n","# alpha'' (alpha-double-prime) feature vector.\n","#\n","# This script requires TensorFlow/Keras.\n","# In Colab, run: !pip install tensorflow\n","\n","print(\"--- Initializing 1D-CNN Feature Extractor (Step 2) ---\")\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import to_categorical\n","\n","print(f\"TensorFlow Version: {tf.__version__}\")\n","\n","# --- PART 1: Configuration ---\n","\n","# --- File Paths ---\n","BASE_PATH = \"/content/drive/MyDrive/1 Skripsi/\"\n","DATA_FILE = os.path.join(BASE_PATH, \"VPNOnly-cnn_payload_data.npy\")\n","LABELS_FILE = os.path.join(BASE_PATH, \"VPNOnly-cnn_payload_labels.csv\")\n","\n","# --- Output Files ---\n","# The new feature set\n","OUTPUT_ALPHA_V3_FILE = os.path.join(BASE_PATH, \"VPNOnly-alpha_double_prime_component_v3.csv\")\n","# The saved encoder model for future use\n","OUTPUT_ENCODER_MODEL_FILE = os.path.join(BASE_PATH, \"VPNOnly-cnn_encoder_v3.keras\")\n","\n","# --- Model Parameters ---\n","# From Step 1, we know these are (10, 784)\n","N_PACKETS = 10\n","PAYLOAD_LEN = 784\n","# We will reshape to (10 * 784, 1)\n","INPUT_SHAPE = (N_PACKETS * PAYLOAD_LEN, 1) # (7840, 1)\n","\n","FEATURE_VECTOR_SIZE = 128 # The width of our new alpha'' feature\n","RANDOM_STATE = 42\n","\n","# --- PART 2: Load & Prepare Data ---\n","def load_and_prepare_data():\n","    print(f\"Loading data from {DATA_FILE}...\")\n","    X = np.load(DATA_FILE)\n","    df_y = pd.read_csv(LABELS_FILE)\n","\n","    print(f\"Loaded data shape: {X.shape}\")\n","    print(f\"Loaded labels shape: {df_y.shape}\")\n","\n","    # --- 1. Reshape X ---\n","    # Reshape (samples, 10, 784) -> (samples, 7840, 1)\n","    # This treats the 10 packets as one long 1D sequence\n","    X_reshaped = X.reshape(X.shape[0], N_PACKETS * PAYLOAD_LEN, 1)\n","    print(f\"Reshaped X to: {X_reshaped.shape}\")\n","\n","    # --- 2. Encode y ---\n","    # We will train the CNN to predict the 'application'\n","    y_labels = df_y['application']\n","    num_classes = len(y_labels.unique())\n","    print(f\"Target label: 'application' with {num_classes} classes.\")\n","\n","    # a. String labels to integer\n","    le = LabelEncoder()\n","    y_int = le.fit_transform(y_labels)\n","\n","    # b. Integer labels to one-hot vectors (for categorical_crossentropy)\n","    y_categorical = to_categorical(y_int)\n","\n","    print(f\"y shape after one-hot encoding: {y_categorical.shape}\")\n","\n","    return X_reshaped, y_categorical, df_y, num_classes\n","\n","# --- PART 3: Build 1D-CNN Model ---\n","def build_model(num_classes):\n","    print(\"Building 1D-CNN model...\")\n","\n","    input_layer = Input(shape=INPUT_SHAPE)\n","\n","    # Convolutional Block 1\n","    x = Conv1D(filters=32, kernel_size=7, activation='relu', padding='same')(input_layer)\n","    x = MaxPooling1D(pool_size=4)(x)\n","\n","    # Convolutional Block 2\n","    x = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same')(x)\n","    x = MaxPooling1D(pool_size=4)(x)\n","\n","    # Convolutional Block 3\n","    x = Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(x)\n","    x = MaxPooling1D(pool_size=4)(x)\n","\n","    x = Flatten()(x)\n","\n","    # --- This is our Feature Vector ---\n","    # We give it a name so we can easily extract it later\n","    x = Dense(FEATURE_VECTOR_SIZE, activation='relu', name=\"encoder_output\")(x)\n","    x = Dropout(0.5)(x)\n","    # ----------------------------------\n","\n","    # Output classifier layer\n","    output_layer = Dense(num_classes, activation='softmax', name=\"classifier_output\")(x)\n","\n","    # Create the full model\n","    model = Model(inputs=input_layer, outputs=output_layer)\n","\n","    model.compile(\n","        optimizer='adam',\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","\n","    print(model.summary())\n","    return model\n","\n","# --- PART 4: Main Execution ---\n","def main():\n","    if not all([os.path.exists(DATA_FILE), os.path.exists(LABELS_FILE)]):\n","        print(f\"FATAL ERROR: Missing {DATA_FILE} or {LABELS_FILE}\")\n","        print(\"Please run Step 1 (extract_cnn_payloads.py) first.\")\n","        return\n","\n","    # --- 1. Load Data ---\n","    X_full, y_full, df_labels, num_classes = load_and_prepare_data()\n","\n","    # --- 2. Split Data for Training ---\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X_full, y_full,\n","        test_size=0.2, # 20% for validation\n","        random_state=RANDOM_STATE,\n","        stratify=y_full\n","    )\n","\n","    print(f\"Training data: {X_train.shape}, Validation data: {X_val.shape}\")\n","\n","    # --- 3. Build & Train Model ---\n","    model = build_model(num_classes)\n","\n","    early_stopping = EarlyStopping(\n","        monitor='val_loss',\n","        patience=10, # Stop if val_loss doesn't improve for 10 epochs\n","        restore_best_weights=True # Restore the best model\n","    )\n","\n","    print(\"\\n--- Starting 1D-CNN Training ---\")\n","    history = model.fit(\n","        X_train, y_train,\n","        epochs=100, # Max epochs\n","        batch_size=64,\n","        validation_data=(X_val, y_val),\n","        callbacks=[early_stopping]\n","    )\n","    print(\"--- Training Complete ---\")\n","\n","    # --- 4. Create and Save the Encoder ---\n","    print(\"Extracting and saving the encoder model...\")\n","\n","    # Create a new model that ends at our named \"encoder_output\" layer\n","    encoder_model = Model(\n","        inputs=model.input,\n","        outputs=model.get_layer(\"encoder_output\").output\n","    )\n","\n","    encoder_model.save(OUTPUT_ENCODER_MODEL_FILE)\n","    print(f\"Encoder model saved to: {OUTPUT_ENCODER_MODEL_FILE}\")\n","\n","    # --- 5. Generate and Save alpha'' Features ---\n","    print(f\"Generating {FEATURE_VECTOR_SIZE}-dimension alpha'' features for all {X_full.shape[0]} samples...\")\n","\n","    # Use the encoder to predict (extract features) on the *entire* dataset\n","    alpha_prime_prime_features = encoder_model.predict(X_full, batch_size=128)\n","\n","    print(f\"Generated features with shape: {alpha_prime_prime_features.shape}\")\n","\n","    # Create a DataFrame for the new features\n","    alpha_cols = [f'alpha_pp_{i}' for i in range(FEATURE_VECTOR_SIZE)]\n","    df_alpha_pp = pd.DataFrame(alpha_prime_prime_features, columns=alpha_cols)\n","\n","    # Combine with the original labels (for merging later)\n","    # We take the 'filename' from df_labels\n","    df_final_alpha = pd.concat([df_labels['filename'], df_alpha_pp], axis=1)\n","\n","    # Save to CSV\n","    df_final_alpha.to_csv(OUTPUT_ALPHA_V3_FILE, index=False)\n","    print(f\"New alpha'' (v3) component saved to: {OUTPUT_ALPHA_V3_FILE}\")\n","    print(\"\\n--- 1D-CNN Feature Extractor Finished ---\")\n","\n","if __name__ == \"__main__\":\n","    if not os.path.exists(\"/content/drive/MyDrive\"):\n","        print(\"Please mount your Google Drive first!\")\n","    else:\n","        main()"]},{"cell_type":"code","source":[],"metadata":{"id":"tIaDWEFDhewr"},"execution_count":null,"outputs":[]}]}